# Chapter 5 - Working with Docker Containers

Now that we are familiar with how to build an image, let's take a closer look at the containers created from those
images and how to control and configure them.

## What Are Containers?

Virtualisation systems such as VMware and Xen enable you to run a complete Linux kernel and OS on top of a 
virtualised layer called a __hypervisor.__ This technique results in a high level of isolation between virtual
machines, since each hosted kernel sits in separate __memory space__ and has __defined entry points__ into the
host's hardware.

__Containers__ take a very different approach, where all containers share the same instance of the Linux kernel,
and any isolation is enforced entirely within that kernel; this approach is called __operating system
virtualisation.__ A succinct definition of a container is as follows: "A container is a self-contained execution
environment that shares the kernel of the host system and which is (optionally) isolated from other containers
in the system". The most obvious advantage containers have over virtual machines is that they don't require 
anywhere near the resources the latter does. Sharing a kernel means that there is one fewer __layers of 
indirection__ between the isolated task (the container) and the hardware it is running on. Rather than entire
second kernel being instantiated, there is instead a little shim placed inside the existing kernel.

A side-effect of this approach is that you can only run Linux-based processes within a container, as they must
be compatible with the underlying kernel; contrast this with virtual machines, which can construct an environment
on top of whatever kernel is required. For this reason it is very important not to conflate containers with 
virtual machines, and to instead think of them as simply being wrappers around processes that are actually running
on the server.

## History of Containers

Much of the advancements that make Docker possible have been developed over the last 30 years, in several different
areas; a __system call__ added to the Unix kernel in the late 1970s and tooling built on modern Linux are key
foundations that Docker is built upon.
 
The idea of isolating and encapsulating part of a running system is an old idea, dating back to the very first
__batch processing systems.__ These would run one program, then switch to run another, making sure that the two
were isolated from one another in order to avoid unintended interaction.

The first true step towards making a modern container was the `chroot` system introduced to Version 7 Unix in 
1979, which is used to restrict the parts of the underlying filesystem that a process has access to. It is 
commonly used to guard the OS against publicly exposed and therefore untrusted server processes like FTP, 
BIND and Sendmail.

Over the next two decades, many Unix variants were created to have multiple tightly controlled domains running on
the same Unix kernel; processes run in one of these domains would have its view of the host's filesystem severely
limited so that there was no chance of processes interacting with processes on different domains. While most
mainstream Unix implementations were not capable of implementing this idea, the Sidewinder
firewall version of Unix, built on top of BSDI Unix, was a popular implementation that did so.

When FreeBSD 4.0 was released in the year 2000, it included a new `jail` command, which enabled 
__shared-environment hosting providers__ to segregate their processes from those of their customers by 
expanding upon `chroot`'scapabilities and enabling processes to be restricted within 'jails', which rendered 
them incapable of interacting with either the underlying file system or processes in other jails.
 
The first major commercial use of container-based technology arrived in 2004 when Sun released an early build of
Solaris 10, which is still used commercially by many to this day; in 2007, HP released __Secure Resource 
Partitions,__ later renamed as __HP-UX Containers.__ Finally, Linux joined the game in 2008 with __Linux Containers 
(LXC)__ which were introduced as part of version 2.6.24 of the Linux kernel; however, it wasn't until 2013 the
community began to gather around Linux Containers, when user namespaces were added to version 3.8 of the Kernel, 
and Docker was released a month later.

The exponential growth of the internet caused major companies such a Google to seek solutions for scaling their
applications, and many became early adopters of container technology in order to distribute their services across
entire data centres full of computers as a means of keeping up with demand. As the tech community started to realise
the need for container-based technology, many companies started to develop in-house solutions, while Google
contributed to the Linux kernel itself in an attempt to improve the tools available in this area.

Eventually the Linux Container frenzy boiled over, with the open source version of Google's container-based
solution, __lmctfy,__ being released only a few months after Docker was unveiled to the world; additional 
alternatives also sprang up, notably __CoreOS Rocket,__ which has the stated intention of rectifying what some
argue are serious deficiencies in the approach Docker takes to containerisation.

## Creating a Container

While in the previous chapter we used the `docker run` command to spin up a container from an image, this is really
a convenience command which first creates the container from the image, and the executes it - these steps can be
achieved individually using the `docker create` and `docker start` commands.

Any configuration options you wish to apply to container can be added to the `docker run` or `docker create` 
commands, such as the `-p` argument to link a host port to a port on the container, or `-e` to specify environment
variables. Below are some more configuration options you might use.

### Basic Configuration

While you can specify many of these settings in your Dockerfile, you can override them by passing arguments to the
command you use to create your container.

#### Container name

You can name your container using the `--name` argument. If you omit this argument, Docker will name your container
for you using a random adjective followed by a random famous coder's name. Each container must have a name unique
to that Docker host.

#### Labels

As we explored in Chapter 4, you may specify labels in your Dockerfile to provide an image with searchable 
key-value pairs as metadata; you may also add new labels at image creation using `labels -l key=value -l name=Sam`, 
etc. and then filter containers using `docker ps -a -f label=name=Sam`. Using `docker inspect` will also include
any labels a container in the resulting readout.

#### Hostname

Docker's default behaviour is to copy certain system files from the host to the container when it is created, such
as `/etc/hostname` to the wherever the host's configuration directory is for that container; it then uses a __bind
mount__ to link that copied file into the container itself.

For demonstration purposes, we'll `run` a container using the `--rm` argument, telling it to delete the container
once it is exited, and the `-i` and `-t` arguments for respectively starting an interactive session and allocating
 a __pseudo-TTY.__ Finally we'll specify that we want to run a `/bin/bash` command so that we can open a bash
session within the container. Put together, the command is as follows.
```
docker run --rm -it ubunt:latest /bin/bash
```
Once the container is running, you can use the `mount` command to see a list of all the bind mounts that have been
mounted to the container. When you use a bind mount, a file or directory from the host machine is mounted into the
container; since it does this by referencing the filepath location on the host machine, this technique relies upon 
the Docker host having a specific directory structure, making the container less portable. Modern Docker apps tend 
to use named volumes instead of bind mounts. The bind mount we are interested in looks like this:
```
/dev/sda1 on /etc/hostname type ext4 (rw,relatime,data=ordered)
```
This shows us that Docker has linked the container's /etc/hostname to the hostname file Docker has placed on the 
host machine, which by default is set to the container's randomly generated ID. We can assign a hostname ourselves
using the `--hostname="your-hostname-here""` argument, and we can check the hostname by running `hostname -f`
inside the container.

#### Domain Name Service (DNS)

The host's resolv.conf file is copied by default into the container's /etc folder and managed via a bind mount in 
the same way as the /etc/hostname file; we can override this behaviour using the `--dns=` and `--dns-search=`
commands to respectively specify 'nameserver' and 'search' fields.
 
#### Media Access Control (MAC) address

By default, a container will receive a __calculated MAC address__ that starts with the __02:42:ac:11__ prefix.
While you are unlikely to want to modify this behaviour, you can add a `--mac-address=` argument in case, for 
instance, you want to reserve a particular set of MAC addresses for your containers in order to avoid conflict
with other virtualisation layers on the same __private block__ as Docker. Be very careful if you choose to do 
this as you may cause __ARP contention__ if two systems advertise the same MAC address.

#### Storage Volumes

While it is not generally advisable to mount storage from a Docker host to container since the container is then
dependent upon being deployed on a particular host in order to function, there are cases in which it makes sense
to do so, such as for __temporary cache files__ or other __semi-ephemeral__ states.
 
In these cases we can use the `-v` command to mount a filesystem on the host server to the container as a 
__volume__ as follows:
```
docker run --rm -it -v /mnt/session_data:/data ubuntu:latest /bin/bash
```
Here, we are mounting the filesystem found at /mnt/session_data on the host system to the /data directory in the
container. Volumes get mounted with read-write privileges, and the mount point in the container does not need to 
already exist.

The outcome of mounting a volume is that any files added, deleted or changed within the container's specified
directory will also occur in the specified host's directory, enabling you to persist files on the host system
after the container has been destroyed.

Docker 1.5 added a `--read-only=true` to allow us to prevent the container's __root volume__ from writing anything
the host's root filesystem, for cases in which logfiles can unexpectedly fill up a container's allocated disk in
production. Mounted volumes can then be used to ensure that the container is only able to write data to the 
specified locations.

Keep in mind that engineers should make every effort to create stateless containers wherever possible, as any 
persistent storage management makes a container much more difficult to deploy.
 
#### Resource Quotas