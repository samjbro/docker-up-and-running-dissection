# Introduction

### The Birth of Docker 
Docker was created by Solomon Hykes, CEO of dotCloud, and unveiled at the
[2013 Python Developers Conference](https://www.youtube.com/watch?v=wW9CAH9nSLs&feature=youtu.be) 
and within a year the entire industry had heard of it.

### The Promise of Docker
Although Docker is primarily thought of as a _virtualisation platform,_ Docker is much more than this -
the segment of development that it disrupts includes both virtualisation products _and_ configuration
management tools, which is unprecedented. This dual-focus on virtualisation and productivity boosting
is what lends Docker such enormous potential.

When comparing Docker to the specialised tools from each of the areas in which it competes it doesn't 
stand out, but what makes it truly special is the way in which it breaks down the barriers between
these previously segregated challenges. It combines the application deployment of Capistrano or Fabric 
with virtual system administration, and also provides hooks that enable simple workflow automation and
orchestration.

Docker is not a flash-in-the-pan fad technology, as it might be were it only useful for virtualisation or 
deployment.

An aspect of development that can easily get lost when focusing on individual challenges is that of
coordination between teams. The more sophisticated the development process gets, the more complex
the coordination tends to become - Docker provides an elegant salve to this problem by consolidating
these processes into a much more manageable state, provided that they are set up well.

One of the greatest challenges of growing a tech-based business is in scaling the development and 
operations skills that the tech team needs to in order to support a larger and larger application,
and as things become more skill-intensive team members tend to become more specialised. While it is 
good to have specialists, it can be easy for the ties that bind specialisms together to become neglected
as the team members become more myopic in their areas of expertise.

Much of the current communication between dev and ops teams is only necessary in order to plug these gaps 
between specialisms, and would become redundant were the gaps to be filled somehow. For example, a dev
asking an ops for a particular release of a library is far less efficient than the dev being able to
simple upgrade the version of the library they are using themselves. Similarly, if an ops could upgrade
the software they are using on a host system without input from dev teams then they too could work
more efficiently. Docker achieves all this by building a __layer of software isolation,__ reducing the
need for human-level coordination.

In addition to lightening the communication load, Docker's structure encourages good software design.
Disposable containers are at the core of Docker's philosophy, and developers who embrace this concept
will build applications that simply cannot rely on artifacts from previous releases, since those artifacts
wouldn't survive the death of their container; the same goes for sloppy, temporary debugging changes introduced
on individual host systems. Applications designed in this way will also be highly portable due to any state
necessarily being immutable or externally stored.
 
Docker-based applications are therefore more __scalable__ and __reliable.__ These techniques have all been
best practice for some time, but Docker enforces them.

### Benefits of the Docker Workflow
Docker comes with its benefits and challenges, but the former outweigh the latter.

1) Applications are packaged in such a uniform and regular way that they can be deployed predictably and with
ease on a host system.
2) Tooling becomes more independent and shareable.
3) The breadth of knowledge required to navigate the various software packaging tools has until now required
specialised engineers; Docker wraps up all these requirements into one package, defined in a single file.
4) Since Docker packages the application together with the Operating System it needs to be run on, an engineer
can be sure that the environment will contain everything the application needs, circumventing cases wherein
one might attempt to run an application on a slightly different version of an OS, and run into dependency issues.
5) Docker's use of __packaged artifacts__ means that engineers can be sure that the application will run
identically on any system to which it is deployed; this makes the testing/deployment cycle much smoother,
since there is no need to recompile or repackage the application between stages.
6) Containers allow for all the benefits of virtual machines - principally enabling a level of abstraction
between the software and the host machine it is run on - but while VMs are very resource-intensive, containers
are __process-based,__ and can utilise more or fewer resources in the same way as any other process running on
a machine.

While Linux containers have been around for more than a decade, Docker finally integrates them into a practical
workflow, finally allowing engineers to reap the benefits Linux containers have always promised.

Docker has an enormous level of support and enthusiasm from the community, and this interest has helped spur
the technology along at a fast pace.

### What Docker isn't
While Docker has enormous breadth in its potential applications, its lack of specificity means that it is not
always a replacement for existing tools in each of the areas it touches. While some companies may find that
it can handily replace their __configuration management tool,__ for instance, others have made use of Docker's
compatibility with these other tools in order to augment both.

1) __Enterprise Visualisation Platform (VMware, KVM, etc.):__ Virtual machines enable the simultaneous 
running of several different virtual machines, potentially with vastly different operating systems - Docker
containers on the other hand share a linux kernel with the host machine. (Not sure how this works with 
Windows or Mac).
2) __Cloud Platform (Openstack, CloudStack, etc.):__ Cloud platforms are similar to Docker containers in that
they enable an application to be __horizontally scaled__ to adapt to variable demand; however the former
allows the creation of new __host systems (instances),__ __object stores,__ __block storage,__ and many other
resources, while Docker only handles deploying, running and managing containers on a pre-existing host.
3) __Configuration Management (Puppet, Chef, etc.):__ While Docker can take over much of a configuration
management tool's role, it cannot manage a container's __ongoing state__ or the Docker __host system,__ since
it is only able to define how the container should be built.
4) __Deployment Framework (Capistrano, Fabric, etc.):__  While Docker can streamline the deployment process
by creating images that encapsulate all of an application's necessary dependencies, it cannot orchestrate
a complex deployment process on its own.
5) __Workload Management Tool (Mesos, Fleet, etc.):__ Docker has no concept of joining containers together into
a __cluster__ that forms a working application - it must rely on other tools such as Docker Swarm to 
coordinate and track containers working in concert.
6) __Development Environment (Vagrant, etc):__ Vagrant is a __virtual machine management tool__ that can be
used to simulate the server stacks of a deployment environment. Boot2Docker and Docker Machine have similar
functionality, but not to the same level of competence.

A primary obstacle to understanding Docker can be the lack of the proper context, since it spans such a
broad spectrum of software engineering concepts. The following chapter will attempt to supply some of this
context.